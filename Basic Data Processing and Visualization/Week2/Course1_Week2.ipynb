{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Assignment\n",
    "\n",
    "This week we reviewed how we can use Python to analyze data. We then learned about CSV and JSON files and how to read them in Python.\n",
    "\n",
    "\n",
    "## Part 1: Reading CSV Files\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "Today, we will be using a dataset containing SAT scores from 2010. You can find this dataset in your Week 2 folder.\n",
    "\n",
    "Source: https://catalog.data.gov/dataset/sat-college-board-2010-school-level-results-5c6d6\n",
    "\n",
    "### Reading the File\n",
    "Specify the path of the file you’d like to read. You may need to change the given path according to your local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE: \n",
    "# Windows: path = \"c://Users/YourName/Downloads/2010_SAT_Results.tsv.gz\"\n",
    "# Mac:     path = \"/Users/YourName/Downloads/2010_SAT_Results.tsv.gz\"\n",
    "path = \"/Users/Grace/Downloads/2010_SAT.tsv.gz\"\n",
    "path = \"/Week1/datasets/2010_SAT_Results.tsv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is gzipped (file type is “.gz”). **What library would you import to read zipped data directly from the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the code in brackets.\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this library, we can open the data as if it were a regular file. `rt` converts the file from bytes to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Week1/datasets/2010_SAT_Results.tsv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a32683431d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pydev3/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydev3/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Week1/datasets/2010_SAT_Results.tsv.gz'"
     ]
    }
   ],
   "source": [
    "f = gzip.open(path, 'rt', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the first line of the dataset using either the `next` function or the `readline` function. Enter your output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-21cfe9bc9996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;31m# see the output of “header” here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "header = f.readline()\n",
    "header # see the output of “header” here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### header:\n",
    "### // TODO Change this text cell; copy-paste your output of the first line here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line is called the \"header\", but it doesn't look very friendly. Note that it contains the names of the fields we expect to find in the file. These fields are separated by tabs (`\\t`) in a tsv file.\n",
    "\n",
    "We can extract these fields to a **list** using the `split` function, which separates the string on the tab character. We can also use the `strip` function to remove leading characters such as spaces to the left and right of the argument.  Use `header = header.strip().split('\\t')` and enter what your header looks like after this.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School Name',\n",
       " 'Number of Test Takers',\n",
       " 'Critical Reading Mean',\n",
       " 'Mathematics Mean',\n",
       " 'Writing Mean']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = header.strip().split('\\t')\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned header:\n",
    "\n",
    "['School Name',\n",
    " 'Number of Test Takers',\n",
    " 'Critical Reading Mean',\n",
    " 'Mathematics Mean',\n",
    " 'Writing Mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `readline` function to output the next line. Be sure to eliminate tabs and extra leading characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Henry Street School for International Studies \\t31\\t391\\t425\\t385\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextline = f.readline()\n",
    "nextline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our lists, let’s start putting the data into a form we can work with! Use a for-loop to extract every line from the file `f` into an array called `lines`, using the `split` and `append` functions. Recall that these fields are separated by tabs (`\\t`) in a tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in f:\n",
    "    fields = line.split('\\t')\n",
    "    lines.append(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a header with our categories and every line in the file. Let's start making our actual dataset. Using a for-loop, match up every single line in the `lines[]` array (above) to the `header` using Python’s **dictionary** data structure and the `zip` function. Then, append the line to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall: This is how you convert the first line in the file to a dictionary, \n",
    "# where the Key is the field name and Value is the corresponding value in lines.\n",
    "# d = dict(zip(header, lines[0]))\n",
    "\n",
    "dataset = []\n",
    "for line in lines:\n",
    "# Convert to key-value pairs\n",
    "    d = dict(zip(header, line))\n",
    "    # Convert strings to integers for some fields:\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily perform queries on any entry in our dataset. Review the lecture videos if you forgot how to access fields in the dictionary. **What is the value of Mathematics Mean’s 123rd row?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'382'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathmn_123 = dataset[123]['Mathematics Mean']\n",
    "mathmn_123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Python - Let's do it faster!\n",
    "\n",
    "Well done, you have a dataset ready to work with! What you just did above is actually the equivalent of the code below. Python gives us a shortcut for reading in a csv file with the `csv.reader` command. \n",
    "\n",
    "Study the code below - it is attaching the lines to the header using Python’s “dictionary” data structure like we did above, and avoids assigning the header to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'School Name': 'HIGH SCHOOL ENVRNMNTL STUDIES ',\n",
       " 'Number of Test Takers': '216',\n",
       " 'Critical Reading Mean': '465',\n",
       " 'Mathematics Mean': '480',\n",
       " 'Writing Mean': '448'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You do not need to change the code below.\n",
    "import csv # import this library whenever you use the below command\n",
    "import gzip\n",
    "\n",
    "all_lines = csv.reader(gzip.open(path, 'rt'), delimiter = '\\t')\n",
    "dataset = []\n",
    "\n",
    "# Start appending lines to dataset\n",
    "first = True\n",
    "for line in all_lines:\n",
    "    \n",
    "    # The first line is the header\n",
    "    if first:\n",
    "        header = line\n",
    "        first = False\n",
    "    else:\n",
    "        d = dict(zip(header, line))\n",
    "        dataset.append(d)\n",
    "\n",
    "# What's in your dataset's 20th row?\n",
    "dataset[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing the Data\n",
    "What if you only want to extract parts of the data? You can do this for large datasets, manipulating it one bit at a time. Let's try getting the three fields `Number of Test Takers`, `Critical Reading Mean`, and `Writing Mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "header = f.readline().strip().split('\\t')\n",
    "\n",
    "\n",
    "# Start appending lines to dataset\n",
    "for line in f:\n",
    "    line = line.split('\\t')\n",
    "    d = dict(zip(header, line))\n",
    "    \n",
    "    # Converting Data Types: \n",
    "    # Use the line below when you have some numerical field as strings\n",
    "    # and want to convert the column to a numerical type.\n",
    "    # In this example, all our columns are numerical, and so do not need to be converted.\n",
    "    \n",
    "    # d['field_name'] = int(d['field_name'])\n",
    "    \n",
    "    # Capture the fields we want row by row\n",
    "    d2 = {}\n",
    "    for field in [ 'Number of Test Takers', 'Critical Reading Mean', 'Writing Mean' ]: \n",
    "        d2[field] = d[field]\n",
    "    dataset.append(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of Test Takers': '71',\n",
       " 'Critical Reading Mean': '424',\n",
       " 'Writing Mean': '423\\n'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the results!\n",
    "dataset[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Check \n",
    "1. How would you access a specific row or value in your dataset?\n",
    "2. What do the empty curly brackets mean in Python (e.g. `d2 = {}`)?\n",
    "3. How does the line of code `d2[field] = d[field]` affect `d2`?\n",
    "4. Why do we append `d2` instead of `d`?\n",
    "5. How would you convert a column of strings to a column of integers?\n",
    "\n",
    "You do not have to answer these officially, but you should go back and review the code if you don't know the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Reading JSON from a File\n",
    "\n",
    "Another common data format is JSON (https://www.json.org/). This format generalizes key-value pairs (like those we saw in previous notebooks), by allowing the values to also be key-value pairs (allowing for hierarchical data). We will be using a small dataset created from https://www.json-generator.com to test this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if needed\n",
    "path = \"/Users/Grace/PDP_Notebooks/Week2/datasets/example.json\"\n",
    "f = open(path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first line of this data. Recall that the `open()` function returns a file object which can used to read, write and modify the given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"_id\":\"5c1a010ae61b49b43c4b4864\",\"index\":0,\"age\":35,\"eyeColor\":\"green\",\"name\":\"Wiggins Holman\",\"address\":\"247 Thatford Avenue, Oneida,Puerto Rico, 7233\",\"friends\":[{\"id\":0,\"name\":\"Carmela Hampton\"},{\"id\":1,\"name\":\"Lynda Pittman\"},{\"id\":2,\"name\":\"Cleveland Noble\"}]}\\n']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "lines.append(f.readline())\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's directly convert this to a dictionary, using the `eval` command. `eval` basically runs its given argument as native Python code, which makes it quick and dirty for parsing JSON, but bad for cybersecurity. However, we'll use it here to give you a feel for parsing JSON. Usually, we would `import ast` to be certain that we are executing legitimate Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5c1a010ae61b49b43c4b4864',\n",
       " 'index': 0,\n",
       " 'age': 35,\n",
       " 'eyeColor': 'green',\n",
       " 'name': 'Wiggins Holman',\n",
       " 'address': '247 Thatford Avenue, Oneida,Puerto Rico, 7233',\n",
       " 'friends': [{'id': 0, 'name': 'Carmela Hampton'},\n",
       "  {'id': 1, 'name': 'Lynda Pittman'},\n",
       "  {'id': 2, 'name': 'Cleveland Noble'}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = eval(lines[0])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then treat `d` like any other key-value pair that you have already dealt with in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can treat it like a dictionary!\n",
    "d['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Saving Private Data\n",
    "Since `eval` isn't too great for building robust programs, let's try another way. We can import the very convenient **json library** to do the heavy lifting, replacing `eval` from above with `json.loads` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5c1a010ae61b49b43c4b4864',\n",
       " 'index': 0,\n",
       " 'age': 35,\n",
       " 'eyeColor': 'green',\n",
       " 'name': 'Wiggins Holman',\n",
       " 'address': '247 Thatford Avenue, Oneida,Puerto Rico, 7233',\n",
       " 'friends': [{'id': 0, 'name': 'Carmela Hampton'},\n",
       "  {'id': 1, 'name': 'Lynda Pittman'},\n",
       "  {'id': 2, 'name': 'Cleveland Noble'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "d = json.loads(lines[0])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to read in a basic JSON file, let's explore a little further with the JSON data structure.\n",
    "\n",
    "Using a for-loop, let's read in the first 7 lines of this JSON file. You may find `readline`, `append`, and the JSON library helpful. You want to read in a line from the file, convert it into Python, and then append it to the `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if needed\n",
    "path = \"/Users/Grace/PDP_Notebooks/Week2/datasets/example.json\"\n",
    "f = open(path, 'r')\n",
    "\n",
    "dataset = []\n",
    "for i in range(7):\n",
    "    dataset.append(json.loads(f.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '5c1a010ae61b49b43c4b4864',\n",
       " 'index': 0,\n",
       " 'age': 35,\n",
       " 'eyeColor': 'green',\n",
       " 'name': 'Wiggins Holman',\n",
       " 'address': '247 Thatford Avenue, Oneida,Puerto Rico, 7233',\n",
       " 'friends': [{'id': 0, 'name': 'Carmela Hampton'},\n",
       "  {'id': 1, 'name': 'Lynda Pittman'},\n",
       "  {'id': 2, 'name': 'Cleveland Noble'}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first line in the dataset you created\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of these values are *themselves* key-value pairs!\n",
    "\n",
    "#### Knowledge Check\n",
    "1. What do the two inputs in `open(path, 'r')` mean?\n",
    "2. Give an example of an entry in your dataset that is itself a key-value pair. How would you access it? A sub-field of it?\n",
    "3. What are the 3 Python libraries you imported in this notebook, and what do each of them allow you to accomplish?\n",
    "\n",
    "You do not need to answer these officially, but we encourage you to go back and review the code if you do not know the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Computing Simple Statistics\n",
    "Now that we know how to read in a file, let's manipulate a few numbers using the Wine Dataset. The cells below will load the dataset using the method you've seen in Parts 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"fixed acidity\"', '\"volatile acidity\"', '\"citric acid\"', '\"residual sugar\"', '\"chlorides\"', '\"free sulfur dioxide\"', '\"total sulfur dioxide\"', '\"density\"', '\"pH\"', '\"sulphates\"', '\"alcohol\"', '\"quality\"']\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/Grace/PDP_Notebooks/Week3/datasets/winequality-red.csv.gz\" # change if needed\n",
    "import gzip\n",
    "file = gzip.open(path, 'rt', encoding = 'utf8')\n",
    "\n",
    "# This data is delimited by semicolons.\n",
    "dataset = []\n",
    "header = file.readline().strip().split(';')\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this\n",
    "header = [head[1:-1] for head in header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for line in file:\n",
    "    fields = line.strip('\\n').split(';')\n",
    "    lines.append(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7.4',\n",
       " '0.7',\n",
       " '0',\n",
       " '1.9',\n",
       " '0.076',\n",
       " '11',\n",
       " '34',\n",
       " '0.9978',\n",
       " '3.51',\n",
       " '0.56',\n",
       " '9.4',\n",
       " '5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the data in the first line?\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the `lines` list into a dictionary with key/value pairs.  \n",
    "**Note that for the sake of brevity, we're only interested in these features: `residual sugar`, `density`, `pH`, `alcohol`, and `quality`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for line in lines:\n",
    "    d = dict(zip(header, line))\n",
    "    # Don't forget to cast the correct data type for each field!\n",
    "    d['residual sugar'] = float(d['residual sugar'])\n",
    "    d['density'] = float(d['density'])\n",
    "    d['pH'] = float(d['pH'])\n",
    "    d['alcohol'] = float(d['alcohol'])\n",
    "    # Instructor's Note: this is important; probably a good 'gotcha' question to have\n",
    "    d['quality'] = int(d['quality'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `dataset`, let's try calculating some simple statistics. We will investigate the number of wines, the average `quality` of the wine, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of wines in the dataset\n",
    "# Make sure there are 1599 entries in the dataset!\n",
    "numWines = len(dataset)\n",
    "numWines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6360225140712945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average quality of all wines in the dataset\n",
    "average = 0\n",
    "for d in dataset:\n",
    "    average += d['quality'] # the quality score for that wine\n",
    "average /= numWines    # the total number of wines\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of unique levels of alcohol less than 10% alcohol (e.g. 9.5, 9.4, 8.0, etc.)\n",
    "numLowAlc = set()\n",
    "for d in dataset:\n",
    "    if d['alcohol'] < 10:\n",
    "        numLowAlc.add(d['alcohol'])\n",
    "\n",
    "len(numLowAlc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.266176470588236, 5.90968443960827)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the average quality of wines with less than 10% alcohol vs that of wines with greater than 10% alcohol.\n",
    "avLowAlc = 0\n",
    "avHighAlc = 0\n",
    "nLowAlc = 0\n",
    "nHighAlc = 0\n",
    "for d in dataset:\n",
    "    if d['alcohol'] < 10:          # Is this wine low in alcohol?\n",
    "        avLowAlc += d['quality']   # Get the quality score for the wine\n",
    "        nLowAlc += 1               # Increment the number of low-alcohol wines\n",
    "    else:\n",
    "        avHighAlc += d['quality']\n",
    "        nHighAlc += 1\n",
    "\n",
    "avLowAlc /= nLowAlc                # Calculate the average quality for each type of wine\n",
    "avHighAlc /= nHighAlc\n",
    "avLowAlc, avHighAlc                # Do you prefer low or high alcohol-content wines? No right answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
