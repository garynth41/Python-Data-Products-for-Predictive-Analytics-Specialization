{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Homework\n",
    "\n",
    "Topics Covered:\n",
    "- Data Filtering and Cleaning\n",
    "    - Filtering by date and attributes\n",
    "- Processing Text and Strings in Python\n",
    "    - Removeing punctuation, making all lowercase\n",
    "- Processing Times and Dates in Python \n",
    "    - Converstion from Strings to Time Objects, to Unix time\n",
    "    - Sorting time feature data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Data Filtering and Cleaning\n",
    "### ...With an introduction to processing Time\n",
    "\n",
    "In this section, you will preprocess a moderately-sized dataset filled with Airbnb Listing Data for Seattle, WA and its surrounding regions.\n",
    "\n",
    "To expidite the assignment, we've written the code needed to import the `airbnb_listings.csv` file.Please begin the assignment by running this code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'room_id', 'host_id', 'room_type', 'address', 'reviews', 'overall_satisfaction', 'accommodates', 'bedrooms', 'bathrooms', 'price', 'last_modified', 'latitude', 'longitude', 'location', 'name', 'currency', 'rate_type']\n"
     ]
    }
   ],
   "source": [
    "# Be sure to run this!\n",
    "import csv\n",
    "\n",
    "f = open('datasets/airbnb_listings.csv')\n",
    "# Note: the delimiter is ',' since this is a csv rather than a tsv file\n",
    "reader = csv.reader(f, delimiter = ',')\n",
    "header = next(reader)\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Be sure to take note of the headers within the dataset.\n",
    "\n",
    "### Task 1:\n",
    "Import the rest of the csv file into a list of dictionaries, simply named `dataset`\n",
    "\n",
    "**Hint**: These are the corresponding headers for each data type:\n",
    "\n",
    "##### Int\n",
    "- index\n",
    "- room_id\n",
    "- host_id\n",
    "- reviews\n",
    "- accommodates\n",
    "- price\n",
    "\n",
    "##### Float\n",
    "- overall_satisfaction\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "- latitude\n",
    "- longitude\n",
    "(some listings list smaller rooms as halves)\n",
    "\n",
    "##### String\n",
    "- Everything else\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for line in reader:\n",
    "    # Convert into a dictionary object\n",
    "    d = dict(zip(header,line))\n",
    "    # Cast ID and Star Ratings as Integers\n",
    "    for field in ['index','room_id','host_id', 'reviews', 'accommodates', 'price']:\n",
    "        d[field] = int(d[field])\n",
    "    for field in ['overall_satisfaction', 'bedrooms', 'bathrooms', 'latitude', 'longitude']:\n",
    "        if(d[field] != ''):\n",
    "            d[field] = float(d[field])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, looks like we've got the dataset up and running. Let's try some filtering techniques we learned in the lecture.\n"
     ]
    }
   ],
   "source": [
    "#Use this to verify that you're on the right track.\n",
    "if(len(dataset) == 7576):\n",
    "    print(\"Great, looks like we've got the dataset up and running. Let's try some filtering techniques we learned in the lecture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that attempting to print the dataset at this point will cause Jupyter to throw an error due to its size.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Filtering by Room Type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start slimming down the dataset. \n",
    "\n",
    "Let's say we're only interested in `room_type` features that are `\"Entire home/apt\"` listings.  \n",
    "Using what we know from the lecture, how would we filter down the dataset by the above criteria? Think about what the line below is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5603\n"
     ]
    }
   ],
   "source": [
    "dataset = [d for d in dataset if d['room_type'] == \"Entire home/apt\"]\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Filtering By Number of Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is printable now, it's still incredibly large (clocking in at 5603 entries!). Let's find another criteria to narrow down the datset to make more meaningful predictions.\n",
    "\n",
    "Let's filter the entireHomeDataset once again by only showing listings that have >= 150 `reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = #TODO: YOUR CODE HERE\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to verify that you are on the right track\n",
    "if(len(dataset) == 423):\n",
    "    print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Strings in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Removing Punctuation and Casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by running the following code snippet below to import Python's `string` library, and by creating a `vocab` list.  \n",
    "We will use this list to collect every word inside the slimmed-down listing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "vocab = []\n",
    "vocabFrequency = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we will...\n",
    "1. Loop through the dataset to remove punctuation  \n",
    "    _Note: You will need to use Python's list of punctuation._\n",
    "2. Make every string lowercase  \n",
    "3. Extend the `vocab` dict with the newly cleaned string, albeit split into individual words.\n",
    "\n",
    "_Hint: Refer to Python's documentation on [common string operations](https://docs.python.org/3.7/library/string.html) to complete this task_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Process the string, then add each word to the compendium\n",
    "for d in dataset:\n",
    "    # Remove punctuation\n",
    "    d['name'] = ''.join(#TODO: YOUR CODE HERE)\n",
    "    # Make lowercase\n",
    "    d['name'] = #TODO: YOUR CODE HERE\n",
    "    # Extend the vocab list by splitting d['name']\n",
    "    vocab.extend(#TODO: YOUR CODE HERE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's append the vocab's count into the vocabFrequency list (this part is done for you). \n",
    "\n",
    "After that, we will zip up the `vocab` and `vocabFrequency` lists into a dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocab:\n",
    "    vocabFrequency.append(vocab.count(word))\n",
    "\n",
    "# Zip up the vocab and vocabFrequency lists into a dictionary object.\n",
    "# Recall the method we used from the previous section to do so. \n",
    "freqDict = #TODO: YOUR CODE HERE\n",
    "# Don't modify this line:\n",
    "freqDict = sorted(freqDict.items(), reverse=True, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "print(freqDict[:10])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the top 10 terms used in the description of each listing. Naturally, since the dataset is focused around the Seattle area, 'seattle' is the top term, clocking in at 70 instances within the subset of our dataset. \n",
    "\n",
    "In a future assignment, we may use the [NLTK Python Library](https://www.nltk.org) to further filter string lists by parts of speech, but that is a topic for a different course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check:\n",
    "1. Name some key reasons why filtering is necessary when working with large datasets.\n",
    "2. What are some features of the `airbnb_reviews` dataset that might not be necessary? Explain your reasoning. \n",
    "3. If you were to remove those features, what would the code for that look like?\n",
    "\n",
    "_You do not need to answer these officially, but we encourage you to go back and review the code if you do not know the answer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Time and Date Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin this section by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "firstTime = dataset[0]['last_modified']\n",
    "print(firstTime)\n",
    "print(type(firstTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the variable `firstTime` is considered a `str` by Python.\n",
    "\n",
    "#### Pause and Reflect:\n",
    "What could be a potential shortcoming of a time feature being represented as a string?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Conversion of firstTime from String, to Tuple, to Unix Time\n",
    "\n",
    "In order to grasp the concept of time casting and conversion, let's modify the `firstTime` variable we created in the prior cells. \n",
    "\n",
    "1. Convert the string to a Time object using a method found [in the documentation for time](https://docs.python.org/3.7/library/time.html).  \n",
    "_Note: Only the first 19 characters in the time string contain relevant time data that we'd like to cast._  \n",
    "_Note 2: Note the date's format (e.g. \"Year-day-month Second:Minute:Hour\" , as printed out in the prior cell. Refer to the list of directives within the documentation to aid with the casting process._\n",
    "\n",
    "2. Print out the `firstTime` variable, and note the way that Time objects are represented in the console output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from String to a Time object\n",
    "firstTime = #TODO: YOUR CODE HERE\n",
    "print(firstTime)\n",
    "print(type(firstTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the slimmed-down dataset from prior sections, let's use our new knowledge to manipulate the time-based features of any given listing.\n",
    "\n",
    "*Hint*: Be sure to leverage the `time.strptime` function to cast the time `str` (strings) as Python `tuple` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's modify every 'last_modified' entry within the dataset\n",
    "for d in dataset:\n",
    "    #Check if the `last_modified` feature of line d is of type string. \n",
    "    #Use an if statement, followed by isinstance. \n",
    "    #TODO: YOUR CODE HERE FOR IF STATEMENT\n",
    "        #Hint: Use the code from the firstTime variable's conversion as an example for the next line.\n",
    "        d['last_modified'] = #TODO: YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the sorting process a bit easier for us, let's convert the Python `time` structs into Unix time. \n",
    "\n",
    "As per the lecture, Unix time is defined as the time (in seconds) since the [Unix Epoch](https://en.wikipedia.org/wiki/Unix_time).\n",
    "\n",
    "*Hint*: Look through the [Python Time Library's Documentation](https://docs.python.org/3.7/library/time.html) to find the function needed to convert struct_time to Unix time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    if isinstance(d['last_modified'], tuple):\n",
    "        d['last_modified'] = #TODO: YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will sort the dataset by `last_modified` feature. To do this, we'll look at [the documentation for Sorting in Python](https://docs.python.org/3/howto/sorting.html#key-functions) â€” specifically the section on Key Functions.\n",
    "\n",
    "This will most likely involve using lambdas. In this case,  since knowledge of lambda functions are not required for this course, we will provide the code snippet below:\n",
    "\n",
    "`lambda x: x['last_modified']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dataset.copy() makes a shallow copy of the dataset.\n",
    "# Leave this line be.\n",
    "sortedByTimeDataset = dataset.copy()\n",
    "\n",
    "sortedByTimeDataset = #TODO: YOUR CODE HERE\n",
    "\n",
    "for d in sortedByTimeDataset:\n",
    "    print(d['last_modified'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UNIX time made it easy to sort the dataset by the `last_modified` field!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check:\n",
    "1. Which method would you use to convert from a Python Time object to a String?\n",
    "2. In what context would you need to perform the above operation?\n",
    "3. Which directive (e.g. %p) would you use to express Minutes as a decimal number (that is, from 00 to 59)?\n",
    "\n",
    "_You do not need to answer these officially, but we encourage you to go back and review the code if you do not know the answer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## You're all done!\n",
    "You should be familiar with the basics of reading in CSV and JSON files now and playing with the data. In your own time, we encourage you to find some datasets and try filtering and cleaning them to slim down extraneous results, or hone in on a specific feature result. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
